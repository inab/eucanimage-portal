<!DOCTYPE html>
<html lang="en">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="UTF-8">
  <title>AI Assessment</title>
  <meta name="description" content="Browse cancer datasets available through the platform.">
  <link rel="shortcut icon" href="/images/favicon.ico">
      <link rel="stylesheet" href="/css/bootstrap.min.css">
    <link rel="stylesheet" href="/css/styles.css">
    <link rel="stylesheet" href="/css/pages.css">
  <header>
  <div class="pb3-m pb6-l">
    <nav class="navbar preload  not-home">
	<div class="container">
		<a href="/" class="logo  not-home">
      <img src="/images/logo.svg" alt="EuCanImage Portal" />		
    </a>
		<ul class="nav-links">
			<li><a href="/" class="">Home</a></li>
			<li><a href="/explore" class="">Explore Data</a></li>
			<li><a href="/ai" class="active">AI Assessment</a></li>
		</ul>
	</div>
</nav>

  </div>
</header>

</head>
<body class="ai">

  <main class="w-100">
    
<section class="explore-hero">
  <div class="w-100">
    <header class="explore-header">
      <div class="hero-pages-content-container">
        <div class="hero-clipped-border"></div>
        <div class="hero-pages-text">
          <h1 class="title">AI Assessment</h1>
          
            <p class="subtitle">Browse cancer datasets available through the platform.</p>
          
        </div>
      </div>
    </header>

    <div class="content container">
      <div class="page-explanation">
  The AI assessment framework in the EuCanImage project includes the Radiomics Quality Score 2.0 (RQS 2.0), which standardizes the evaluation of both deep learning and handcrafted radiomics studies. It incorporates the Radiomics Readiness Levels (RRLs) to provide a structured, stepwise approach to assessing research maturity. The In Silico Trial Platform supports simulated clinical studies to evaluate AI&#39;s impact in three settings: clinicians without AI, with AI, and with AI plus explainability. OpenEBench enables researchers to participate in benchmarking events and access public benchmarking results, promoting transparency and comparability of AI methods. Additionally, the project integrates cost-effectiveness analysis to assess the practical and economic value of implementing AI in clinical workflows.
</div>

<div>
  AI modeling
</div>
<div class="section-repositories flex-container">

  <div class="section-discovery-wrapper mt-5">
  <h2>Access to Services or Software</h2>

    <div class="cards">

      
      <div class="discovery-card flip-in">
        <div class="discovery-card-wrapper">
          <div class="card-header">
            <img src="/images/opeb_logo.gif" alt="OpenEBench logo" class="icon pb-3">
            <h4>OpenEBench</h4>
            <p class="pb-0"><strong>ELIXIR Benchmarking Platform</strong></p>
          </div>
          <div class="card-body">
            <ul>
              <li><img src="/images/right-arrow.png" />Participate to benchmarking events organized by EuCanImage for assessing your AI method</li>
              <li><img src="/images/right-arrow.png" />Inspect and visualize public benchmarking results.</li>
            </ul>
          </div>
          
          
          <a href="https://openebench.bsc.es/benchmarking/OEBC012" target="_blank" class="btn btn-go">GO</a>
        </div>
      </div>

      
      <div class="discovery-card flip-in">
        <div class="discovery-card-wrapper">
          <div class="card-header">
            <img src="/images/default.jpg" alt="OpenEBench logo" class="icon pb-3">
            <h4>In silico Trial Platform</h4>
            <p class="pb-0"><strong>In silico Validation</strong></p>
          </div>
          <div class="card-body">
            <p class="mt-0 pb-0">In silico platform allows to conduct studies to evaluate the added value of AI in the simulated clinical workflow. Three types of evaluations are possible: </p>
            <ul>
              <li><img src="/images/right-arrow.png" />Clinicians without AI</li>
              <li><img src="/images/right-arrow.png" />Clinicians with AI</li>
              <li><img src="/images/right-arrow.png" />Clinicians with AI and Explainability</li>
            </ul>
          </div>
          
          
          <a href="https://insilicoradiomics.eu" target="_blank" class="btn btn-go">GO</a>
        </div>
      </div>

      
      <div class="discovery-card flip-in">
        <div class="discovery-card-wrapper">
          <div class="card-header">
            <img src="/images/default.jpg" alt="OpenEBench logo" class="icon pb-3">
            <h4>Radiomics Quality Score 2.0 </h4>
            <p class="pb-0"><strong>Benchmarking Radiomics Studies</strong></p>
          </div>
          <div class="card-body">
            <ul>
              <li><img src="/images/right-arrow.png" />Radiomics Quality Score 2.0 enables benchmarking deep learning and handcrafted radiomics research.</li>
              <li><img src="/images/right-arrow.png" />The Radiomics Readiness Levels (RRLs) framework is embedded within RQS 2.0 to establish a structured, step-by-step approach to radiomics research.</li>
            </ul>
          </div>

          
          <a href="https://www.radiomics.world/rqs2" target="_blank" class="btn btn-go">GO</a>
        </div>
      </div>
    </div>
    
  </div>
</div>

<div class="section-repositories flex-container" >
  <div class="section-discovery-wrapper repositories-wrapper">
    <h2>Benchmarking Challenges</h2>

    
    <h5 class="text-secondary mt-3">Metrics and scores</h5>

    <div class="section-assessment-wrapper">
      
      <table class="metrics-table">
        <thead>
          <tr>
            <th>Detection Metrics</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Intersection Over Union (IoU)</td>
          </tr>
          <tr>
            <td>Boundary Intersection Over Union (Uncertainity Aware)</td>
          </tr>
          <tr>
            <td>False Positives Per Image</td>
          </tr>
          <tr>
            <td>FROC Curve (AUC-FROC)</td>
          </tr>
          <tr>
            <td>Average Precision at various thresholds (alpha= 0.1 to 0.75)</td>
          </tr>
          <tr>
            <td>Sensitivity at various thresholds (alpha = 0.1 to 0.75)</td>
          </tr>
        </tbody>
      </table>
    </div>

    <div class="section-assessment-wrapper">
      
      <table class="metrics-table">
        <thead>
          <tr>
            <th>Classification Metrics</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>TPR/Sensitivity/Recall</td>
          </tr>
          <tr>
            <td>TNR/Specificity</td>
          </tr>
          <tr>
            <td>PPV/Precision</td>
          </tr>
          <tr>
            <td>NPV</td>
          </tr>
          <tr>
            <td>Accuracy</td>
          </tr>
          <tr>
            <td>F1 Score</td>
          </tr>
          <tr>
            <td>Balanced Accuracy</td>
          </tr>
          <tr>
            <td>Cohen's Kappa</td>
          </tr>
          <tr>
            <td>Weighted Cohen's Kappa</td>
          </tr>
          <tr>
            <td>Mathews Correlation Coefficient</td>
          </tr>
          <tr>
            <td>AUC Receiver Operating Characteristic Curve</td>
          </tr>
          <tr>
            <td>AUC Precision Recall Curve</td>
          </tr>
        </tbody>
      </table>

      
      <table class="metrics-table">
        <thead>
          <tr>
            <th>Segmentation Metrics</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Dice Index</td>
          </tr>
          <tr>
            <td>Surface Dice Index</td>
          </tr>
          <tr>
            <td>Jaccard Index</td>
          </tr>
          <tr>
            <td>Hausdorff Distance</td>
          </tr>
          <tr>
            <td>Hausdorff Distance 95 percentile</td>
          </tr>
          <tr>
            <td>Average Symmetric Surface Distance</td>
          </tr>
          <tr>
            <td>Normalized Surface Distance</td>
          </tr>
          <tr>
            <td>Modified Hausdorff Distance</td>
          </tr>
          <tr>
            <td>Average Distance (2D)</td>
          </tr>
    
        </tbody>
      </table>
    </div>

    
    <h5 class="text-secondary mt-3">Datasets</h5>
    <p>(Controlled) access to datasets we expect to produce. Right now these resources are not yet created, but if we can compile the list of expected assets, Iâ€™ll create a table outlining them:
    </p>

    <div class="section-assessment-wrapper">
      <table class="simple-table">
        <tr>
          <th colspan="2">Dataset Name</th>
          <th rowspan="2">Type</th>
          <th rowspan="2">Private XNAT/EGA link</th>
        </tr>
        <tr>
        </tr>
        <tr>
          <td rowspan="2">UC1</td>
          <td>Image testing Dataset</td>
          <td></td>
          <td>Not available yet</td>
        </tr>
        <tr>
          <td>Ground Truth</td>
          <td></td>
          <td>Not available yet</td>
        </tr>
        <tr>
          <td rowspan="2">UC2</td>
          <td>Image testing Dataset</td>
          <td></td>
          <td>Not available yet</td>
        </tr>
        <tr>
          <td>Ground Truth</td>
          <td></td>
          <td>Not available yet</td>
        </tr>
        <tr>
          <td rowspan="2">UC3</td>
          <td>Image testing Dataset</td>
          <td></td>
          <td>Not available yet</td>
        </tr>
        <tr>
          <td>Ground Truth</td>
          <td></td>
          <td>Not available yet</td>
        </tr>
        <tr>
          <td rowspan="2">UC4</td>
          <td>Image testing Dataset</td>
          <td></td>
          <td>Not available yet</td>
        </tr>
        <tr>
          <td>Ground Truth</td>
          <td></td>
          <td>Not available yet</td>
        </tr>
        <tr>
          <td rowspan="2">UC5</td>
          <td>Image testing Dataset</td>
          <td></td>
          <td>Not available yet</td>
        </tr>
        <tr>
          <td>Ground Truth</td>
          <td></td>
          <td>Not available yet</td>
        </tr>
        <tr>
          <td rowspan="2">UC6</td>
          <td>Image testing Dataset</td>
          <td></td>
          <td>Not available yet</td>
        </tr>
        <tr>
          <td>Ground Truth</td>
          <td></td>
          <td>Not available yet</td>
        </tr>
        <tr>
          <td rowspan="2">UC7</td>
          <td>Image testing Dataset</td>
          <td></td>
          <td>Not available yet</td>
        </tr>
        <tr>
          <td>Ground Truth</td>
          <td></td>
          <td>Not available yet</td>
        </tr>
        <tr>
          <td rowspan="2">UC8</td>
          <td>Image testing Dataset</td>
          <td></td>
          <td>Not available yet</td>
        </tr>
        <tr>
          <td>Ground Truth</td>
          <td></td>
          <td>Not available yet</td>
        </tr>
      </table>
      
    </div>
  </div>
</div>
<div class="section-repositories flex-container" >
  <div class="section-discovery-wrapper repositories-wrapper">
    <h2>Other sections or suggestions?</h2>

    <p>
      Please, let me know if you think we can include any other kind of information it would be valuable to share at the portal for AI data researchers willing to understand/use our AI assessment efforts
      ...
    </p>
  </div>
</div>

    </div>
  </div>
</section>

  </main>

  <footer class="footer-centered bg-custom-blue" role="contentinfo">
  <div class="footer-inner">
    <div class="footer-text">
       &copy; EuCanImage 2025
    </div>
    <div class="footer-social">
      <div class="social-links flex gap-3">
  
    <a href="https://x.com/EuCanImage" target="_blank" aria-label="Twitter">
      <img src="/images/social-media_x.png" alt="Twitter" class="social-icon" />
    </a>
  
</div>
    </div>
  </div>
  <script src="/js/bootstrap.bundle.min.js"></script>
  <script src="/js/navbar-shrink.js"></script>
</footer>

</body>
</html>
